{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "colonial-hurricane",
   "metadata": {},
   "source": [
    "### One-Vs-Rest\n",
    "\n",
    "One-Vs-Rest（ovr）的思想是把一个多分类的问题变成多个二分类的问题\n",
    "\n",
    "<b>这里需要注意的是ovr依然使用sigmoid函数的计算公式</b>\n",
    "\n",
    "* 优点：普适性还比较广，可以应用于能输出值或者概率的分类器，同时效率相对较好，有多少个类别就训练多少个分类器。\n",
    "\n",
    "* 缺点：很容易造成训练集样本数量的不平衡（Unbalance），尤其在类别较多的情况下，经常容易出现正类样本的数量远远不及负类样本的数量，这样就会造成分类器的偏向性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "monetary-single",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "domestic-uncertainty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(120,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = datasets.load_iris(return_X_y=True)  # 150个样本， 3个类别\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1024)  # random_state=1024 随机打乱固定数据\n",
    "display(X_train.shape, X_test.shape)\n",
    "display(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "connected-absolute",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-spokesman",
   "metadata": {},
   "source": [
    "#### ovr建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "compatible-tyler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 2, 0, 0, 1, 2, 1, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 2, 0, 0, 1, 2, 1, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ovr的准确率为： 1.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "multi_class : {'auto', 'ovr', 'multinomial'}\n",
    "auto:默认的参数，根据数据来决定数二分类还是多分类\n",
    "ovr:指定为多分类\n",
    "multinomial:多项式\n",
    "\"\"\"\n",
    "# 准确率\n",
    "from sklearn.metrics import accuracy_score\n",
    "model = LogisticRegression(multi_class='ovr')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "display(y_test[:10], y_pred[:10])\n",
    "print('ovr的准确率为：', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "psychological-complexity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "egyptian-teach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test == y_pred).sum() / 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-florist",
   "metadata": {},
   "source": [
    "#### 概率预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "mounted-disposal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 2, 0, 0, 1, 2, 1, 0])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "obvious-repository",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15343204, 0.83995038, 0.00661758],\n",
       "       [0.81155421, 0.18843433, 0.00001146],\n",
       "       [0.00001368, 0.31458264, 0.68540369],\n",
       "       [0.00087407, 0.43021069, 0.56891524],\n",
       "       [0.79198737, 0.2080071 , 0.00000553],\n",
       "       [0.86110144, 0.13889478, 0.00000378],\n",
       "       [0.00650175, 0.84071974, 0.1527785 ],\n",
       "       [0.00019224, 0.19356487, 0.80624289],\n",
       "       [0.01379238, 0.65811053, 0.32809708],\n",
       "       [0.84337093, 0.15662392, 0.00000516]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "proba = model.predict_proba(X_test)  # 在使用predict_proba函数时，进行了归一化，所以后面进行手动计算时也需要对数据进行归一化\n",
    "proba[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-conversation",
   "metadata": {},
   "source": [
    "#### 概率手动计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bearing-programming",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape  # 150个样本  4个特征 花萼长，宽，花瓣 长宽"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "smaller-schedule",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.45418407,  0.77862646, -2.2268873 , -0.87662661],\n",
       "       [-0.41614677, -1.98168225,  0.82180991, -1.2628189 ],\n",
       "       [-0.28832573, -0.49869581,  2.70303022,  2.23465912]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([  6.82628324,   6.16028196, -13.72510278])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ovr依然使用sigmod函数\n",
    "def sigmoid(X):\n",
    "    return 1 / (1 + np.exp(-X))\n",
    "\n",
    "\"\"\"\n",
    "有几个类别，就有几个分类器，分类器也就是线性方程\n",
    "鸢尾花有三个类别 0,1,2 那么就会有3行  因为有四个特征，所以就会有4列\n",
    "这里的每个方程有4个系数\n",
    "\"\"\"\n",
    "b = model.intercept_\n",
    "\n",
    "# 方程系数  系数由属性决定\n",
    "w = model.coef_  \n",
    "display(w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "legitimate-automation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape  # 一行4个数据 4列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "mechanical-albert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape # 一列 有3个数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cellular-cycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X_test.dot(w.T) + b  # 进行矩阵乘法时，进行行乘以列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "noted-given",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15343204, 0.83995038, 0.00661758],\n",
       "       [0.81155421, 0.18843433, 0.00001146],\n",
       "       [0.00001368, 0.31458264, 0.68540369],\n",
       "       [0.00087407, 0.43021069, 0.56891524],\n",
       "       [0.79198737, 0.2080071 , 0.00000553],\n",
       "       [0.86110144, 0.13889478, 0.00000378],\n",
       "       [0.00650175, 0.84071974, 0.1527785 ],\n",
       "       [0.00019224, 0.19356487, 0.80624289],\n",
       "       [0.01379238, 0.65811053, 0.32809708],\n",
       "       [0.84337093, 0.15662392, 0.00000516]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = sigmoid(y)\n",
    "p = p / p.sum(axis=1).reshape(-1, 1) # 归一化\n",
    "p[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-contest",
   "metadata": {},
   "source": [
    "### Softmax\n",
    "\n",
    "将数据变为概率，数据越大，概率就越大\n",
    "\n",
    "计算公式： $y = e^x / \\sum\\limits_{j = 1}^ke^x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "answering-client",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87887824, 0.11894324, 0.00217852])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(z):\n",
    "    return np.exp(z) / np.exp(z).sum()\n",
    "\n",
    "z = [3, 1, -3]\n",
    "softmax(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "spanish-garbage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "brown-fireplace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(120,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1024)\n",
    "display(X_train.shape, X_test.shape)\n",
    "display(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "private-modern",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "included-tolerance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-zoning",
   "metadata": {},
   "source": [
    "#### 模型训练和预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "selective-hepatitis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax预测的准确率为： 1.0\n",
      "softmax预测测试数据的准确率为：\n",
      " [[0.1530188  0.84270328 0.00427793]\n",
      " [0.94519984 0.05479963 0.00000053]\n",
      " [0.00000014 0.00672261 0.99327725]\n",
      " [0.00040995 0.16393254 0.83565752]\n",
      " [0.96771734 0.0322825  0.00000016]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\envs\\jupy_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(multi_class='multinomial')  # 使用softmax\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.score(X_test, y_test)\n",
    "print('softmax预测的准确率为：', y_pred)\n",
    "print('softmax预测测试数据的准确率为：\\n', model.predict_proba(X_test)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-baltimore",
   "metadata": {},
   "source": [
    "#### 概率手动计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "through-clock",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = model.coef_\n",
    "b = model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "timely-recipe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1530188 , 0.84270328, 0.00427793],\n",
       "       [0.94519984, 0.05479963, 0.00000053],\n",
       "       [0.00000014, 0.00672261, 0.99327725],\n",
       "       [0.00040995, 0.16393254, 0.83565752],\n",
       "       [0.96771734, 0.0322825 , 0.00000016]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sofmax(z):\n",
    "    return np.exp(z) / np.exp(z).sum(axis=1).reshape(-1, 1)\n",
    "\n",
    "y = X_test.dot(w.T) + b\n",
    "sofmax(y)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-reviewer",
   "metadata": {},
   "source": [
    "## softmax实现手写数字分类 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "understood-signature",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-parameter",
   "metadata": {},
   "source": [
    "### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mediterranean-robert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(42000,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('digits.csv')\n",
    "X = data.drop('label', axis=1)\n",
    "y = data['label']\n",
    "display(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-antibody",
   "metadata": {},
   "source": [
    "### 划分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "provincial-columbia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 784)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(8400, 784)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(33600,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(8400,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "display(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-scroll",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "balanced-berlin",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\envs\\jupy_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', solver='sag')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(multi_class='multinomial', max_iter=100, solver='sag')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bronze-burns",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "basic-seattle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "概率为：\n",
      " [[0.         0.00000288 0.99986224 0.00009269 0.         0.00000203\n",
      "  0.00000657 0.         0.00003359 0.        ]\n",
      " [0.00000001 0.         0.00041588 0.9995087  0.         0.0000457\n",
      "  0.         0.00000003 0.00002878 0.0000009 ]\n",
      " [0.         0.00000002 0.00000003 0.0000003  0.00480793 0.00000015\n",
      "  0.         0.00000053 0.00003682 0.99515421]\n",
      " [0.000003   0.0000298  0.00000278 0.00001352 0.99757672 0.00000132\n",
      "  0.00003778 0.00005927 0.00015842 0.0021174 ]\n",
      " [0.00000655 0.00000108 0.0067361  0.00106266 0.00000002 0.0006547\n",
      "  0.00004334 0.         0.9914699  0.00002565]]\n",
      "准确率： 0.9108333333333334\n"
     ]
    }
   ],
   "source": [
    "# np.set_printoptions(suppress=True)\n",
    "print('概率为：\\n', model.predict_proba(X_test)[:5])\n",
    "print('准确率：', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "middle-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = model.coef_ # 10个方程， 784个系数 10个截距"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "separate-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-register",
   "metadata": {},
   "source": [
    "#### 手动实现概率的计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "helpful-attack",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8400, 784)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "central-aviation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 784)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cheap-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = X_test.dot(w.T) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "persistent-subcommittee",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "promising-anderson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41952</th>\n",
       "      <th>41958</th>\n",
       "      <th>41960</th>\n",
       "      <th>41968</th>\n",
       "      <th>41970</th>\n",
       "      <th>41971</th>\n",
       "      <th>41979</th>\n",
       "      <th>41984</th>\n",
       "      <th>41987</th>\n",
       "      <th>41988</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>3.645032e-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.816679</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.555003e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25638</th>\n",
       "      <td>9.386617e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>208010.935280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.682870e-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8536</th>\n",
       "      <td>2.063641e-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.043477e-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17623</th>\n",
       "      <td>1.621559e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.557933e-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21475</th>\n",
       "      <td>1.651919e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.566725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.366399e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8407 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0      1      2              3      4      5             6      \\\n",
       "2095   3.645032e-10    NaN    NaN      22.816679    NaN    NaN  9.555003e-06   \n",
       "25638  9.386617e-07    NaN    NaN  208010.935280    NaN    NaN  8.682870e-14   \n",
       "8536   2.063641e-13    NaN    NaN       0.005548    NaN    NaN  4.043477e-10   \n",
       "17623  1.621559e-07    NaN    NaN       0.001548    NaN    NaN  2.557933e-08   \n",
       "21475  1.651919e-06    NaN    NaN       0.566725    NaN    NaN  1.366399e-07   \n",
       "\n",
       "       7      8      9      ...  41952  41958  41960  41968  41970  41971  \\\n",
       "2095     NaN    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "25638    NaN    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "8536     NaN    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "17623    NaN    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "21475    NaN    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "       41979  41984  41987  41988  \n",
       "2095     NaN    NaN    NaN    NaN  \n",
       "25638    NaN    NaN    NaN    NaN  \n",
       "8536     NaN    NaN    NaN    NaN  \n",
       "17623    NaN    NaN    NaN    NaN  \n",
       "21475    NaN    NaN    NaN    NaN  \n",
       "\n",
       "[5 rows x 8407 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.set_printoptions(suppress=True)\n",
    "def softmax(z):\n",
    "    return np.exp(z) / np.exp(z).sum(axis=1)\n",
    "p = softmax(z)\n",
    "p[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "widespread-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "matched-share",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9108333333333334"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "legitimate-spending",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25f61993b00>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.linspace(-10, 10, 100)\n",
    "def softmax(z):\n",
    "    return np.exp(z) / np.exp(-z).sum()\n",
    "y = softmax(X)\n",
    "plt.plot(X, y, color='g')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "classified-broadcasting",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
