{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "organizational-argument",
   "metadata": {},
   "source": [
    "### One-Vs-Rest\n",
    "\n",
    "One-Vs-Rest（ovr）的思想是把一个多分类的问题变成多个二分类的问题\n",
    "\n",
    "<b>这里需要注意的是ovr依然使用sigmoid函数的计算公式</b>\n",
    "\n",
    "* 优点：普适性还比较广，可以应用于能输出值或者概率的分类器，同时效率相对较好，有多少个类别就训练多少个分类器。\n",
    "\n",
    "* 缺点：很容易造成训练集样本数量的不平衡（Unbalance），尤其在类别较多的情况下，经常容易出现正类样本的数量远远不及负类样本的数量，这样就会造成分类器的偏向性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "strong-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "possible-density",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(120,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = datasets.load_iris(return_X_y=True)  # 150个样本， 3个类别\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1024)  # random_state=1024 随机打乱固定数据\n",
    "display(X_train.shape, X_test.shape)\n",
    "display(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adopted-bulgaria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-slope",
   "metadata": {},
   "source": [
    "#### ovr建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "patent-adams",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 2, 0, 0, 1, 2, 1, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 2, 0, 0, 1, 2, 1, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ovr的准确率为： 1.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "multi_class : {'auto', 'ovr', 'multinomial'}\n",
    "auto:默认的参数，根据数据来决定数二分类还是多分类\n",
    "ovr:指定为多分类\n",
    "multinomial:多项式\n",
    "\"\"\"\n",
    "# 准确率\n",
    "from sklearn.metrics import accuracy_score\n",
    "model = LogisticRegression(multi_class='ovr')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "display(y_test[:10], y_pred[:10])\n",
    "print('ovr的准确率为：', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "involved-variation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "statistical-bottom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test == y_pred).sum() / 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-supplier",
   "metadata": {},
   "source": [
    "#### 概率预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "serial-sweden",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 2, 0, 0, 1, 2, 1, 0])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "grand-norfolk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15343204, 0.83995038, 0.00661758],\n",
       "       [0.81155421, 0.18843433, 0.00001146],\n",
       "       [0.00001368, 0.31458264, 0.68540369],\n",
       "       [0.00087407, 0.43021069, 0.56891524],\n",
       "       [0.79198737, 0.2080071 , 0.00000553],\n",
       "       [0.86110144, 0.13889478, 0.00000378],\n",
       "       [0.00650175, 0.84071974, 0.1527785 ],\n",
       "       [0.00019224, 0.19356487, 0.80624289],\n",
       "       [0.01379238, 0.65811053, 0.32809708],\n",
       "       [0.84337093, 0.15662392, 0.00000516]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "proba = model.predict_proba(X_test)  # 在使用predict_proba函数时，进行了归一化，所以后面进行手动计算时也需要对数据进行归一化\n",
    "proba[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-wireless",
   "metadata": {},
   "source": [
    "#### 概率手动计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "frozen-namibia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape  # 150个样本  4个特征 花萼长，宽，花瓣 长宽"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "explicit-legislature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.45418407,  0.77862646, -2.2268873 , -0.87662661],\n",
       "       [-0.41614677, -1.98168225,  0.82180991, -1.2628189 ],\n",
       "       [-0.28832573, -0.49869581,  2.70303022,  2.23465912]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([  6.82628324,   6.16028196, -13.72510278])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ovr依然使用sigmod函数\n",
    "def sigmoid(X):\n",
    "    return 1 / (1 + np.exp(-X))\n",
    "\n",
    "\"\"\"\n",
    "有几个类别，就有几个分类器，分类器也就是线性方程\n",
    "鸢尾花有三个类别 0,1,2 那么就会有3行  因为有四个特征，所以就会有4列\n",
    "这里的每个方程有4个系数\n",
    "\"\"\"\n",
    "b = model.intercept_\n",
    "\n",
    "# 方程系数  系数由属性决定\n",
    "w = model.coef_  \n",
    "display(w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "korean-season",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape  # 一行4个数据 4列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "wireless-nepal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape # 一列 有3个数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "affected-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X_test.dot(w.T) + b  # 进行矩阵乘法时，进行行乘以列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "every-football",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15343204, 0.83995038, 0.00661758],\n",
       "       [0.81155421, 0.18843433, 0.00001146],\n",
       "       [0.00001368, 0.31458264, 0.68540369],\n",
       "       [0.00087407, 0.43021069, 0.56891524],\n",
       "       [0.79198737, 0.2080071 , 0.00000553],\n",
       "       [0.86110144, 0.13889478, 0.00000378],\n",
       "       [0.00650175, 0.84071974, 0.1527785 ],\n",
       "       [0.00019224, 0.19356487, 0.80624289],\n",
       "       [0.01379238, 0.65811053, 0.32809708],\n",
       "       [0.84337093, 0.15662392, 0.00000516]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = sigmoid(y)\n",
    "p = p / p.sum(axis=1).reshape(-1, 1) # 归一化\n",
    "p[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-garden",
   "metadata": {},
   "source": [
    "### Softmax\n",
    "\n",
    "将数据变为概率，数据越大，概率就越大\n",
    "\n",
    "计算公式： $y = e^x / \\sum\\limits_{j = 1}^ke^x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "handmade-consumer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87887824, 0.11894324, 0.00217852])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(z):\n",
    "    return np.exp(z) / np.exp(z).sum()\n",
    "\n",
    "z = [3, 1, -3]\n",
    "softmax(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "incorrect-handbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "outdoor-facing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(120,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1024)\n",
    "display(X_train.shape, X_test.shape)\n",
    "display(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "static-finger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "involved-equation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-grade",
   "metadata": {},
   "source": [
    "#### 模型训练和预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "comparative-sheriff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax预测的准确率为： 1.0\n",
      "softmax预测测试数据的准确率为：\n",
      " [[0.1530188  0.84270328 0.00427793]\n",
      " [0.94519984 0.05479963 0.00000053]\n",
      " [0.00000014 0.00672261 0.99327725]\n",
      " [0.00040995 0.16393254 0.83565752]\n",
      " [0.96771734 0.0322825  0.00000016]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\envs\\jupy_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(multi_class='multinomial')  # 使用softmax\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.score(X_test, y_test)\n",
    "print('softmax预测的准确率为：', y_pred)\n",
    "print('softmax预测测试数据的准确率为：\\n', model.predict_proba(X_test)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-optics",
   "metadata": {},
   "source": [
    "#### 概率手动计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "burning-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = model.coef_\n",
    "b = model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "lesser-skiing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1530188 , 0.84270328, 0.00427793],\n",
       "       [0.94519984, 0.05479963, 0.00000053],\n",
       "       [0.00000014, 0.00672261, 0.99327725],\n",
       "       [0.00040995, 0.16393254, 0.83565752],\n",
       "       [0.96771734, 0.0322825 , 0.00000016]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sofmax(z):\n",
    "    return np.exp(z) / np.exp(z).sum(axis=1).reshape(-1, 1)\n",
    "\n",
    "y = X_test.dot(w.T) + b\n",
    "sofmax(y)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-pavilion",
   "metadata": {},
   "source": [
    "## softmax实现手写数字分类 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "configured-migration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-history",
   "metadata": {},
   "source": [
    "### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "naughty-understanding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(42000,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('digits.csv')\n",
    "X = data.drop('label', axis=1)\n",
    "y = data['label']\n",
    "display(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-billion",
   "metadata": {},
   "source": [
    "### 划分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "informed-culture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 784)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(8400, 784)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(33600,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(8400,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "display(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-district",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "charitable-lotus",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\envs\\jupy_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=20000, multi_class='multinomial')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(multi_class='multinomial', max_iter=20000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "wired-offense",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 9, ..., 4, 1, 8], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "unauthorized-school",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "概率为：\n",
      " [[0.         0.         0.99998797 ... 0.         0.00000271 0.        ]\n",
      " [0.         0.         0.00010674 ... 0.         0.00000157 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.00000015 0.99781574]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.00463082 0.00000001 0.00132785]\n",
      " [0.         0.99999999 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.99671357 0.00001097]]\n",
      "准确率： 0.8947619047619048\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "print('概率为：\\n', model.predict_proba(X_test))\n",
    "print('准确率：', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bearing-proceeding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_ # 10个方程， 784个系数 10个截距"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "other-michigan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.56655391,  0.20810259,  0.5927771 , -0.7782914 ,  0.13466673,\n",
       "        2.56536953, -0.37733797,  0.63889535, -1.96397824, -0.45364977])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "insured-indianapolis",
   "metadata": {},
   "source": [
    "#### 手动实现概率的计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-contribution",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
